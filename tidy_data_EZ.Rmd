---
title: "read data from Indeed"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = F, 
                      message = F)
library(tidyverse)
library(readr)
library(rvest)
library(stringr)
library(tidytext)
library(wordcloud)
library(RColorBrewer)
theme_set(theme_bw())
```

### read data (existing)

```{r}
datascience <- read_csv("./data/datascience_market/alldata.csv") %>% 
  filter(!is.na(position))
```

### tidy datascience data

minimum requirement of degree

```{r, dpi = 300}
pattern_Hi = "[Hh]igh [Ss]chool"
pattern_Ba = "[Bb]achelor | \\bB\\.?A\\b | \\bB\\.?S\\b | [Cc]ollege | [Dd]egree"
pattern_Ma = "[Mm]aster[^y] | [Aa]dvanced | \\bM\\.?[SA]\\b | [Gg]raduate"
pattern_Phd = "\\b[Pp][Hh]\\.?[Dd]\\b | \\bM\\.?D\\b"

datascience %>% 
  mutate(degree = ifelse(str_detect(.$description, pattern_Hi) == TRUE, "high school",
                      ifelse(str_detect(.$description, pattern_Ba) == TRUE, "bachelor",
                          ifelse(str_detect(.$description, pattern_Ma) == TRUE, "master",
                               ifelse(str_detect(.$description, pattern_Phd) == TRUE, "phd", "other"))))) %>% 
  mutate(degree = factor(degree, levels = c("high school", "bachelor", "master", "phd", "other"))) %>% 
  ggplot(aes(x = degree)) + 
  geom_bar() + 
  labs(title = "Minimum degree requirement")
```

### word frequency count

Took 100 samples from 7000

```{r}
datascience <- mutate(datascience, index = 1:nrow(datascience))
set.seed(1)
sample1 <- sample(1:nrow(datascience), 100, replace = FALSE)
sample1

data_100 <- datascience[sample1,]
```

weâ€™ll un-nest the tokens (i.e. words) in each description; the result is a tidy dataset in which each word is contained within a separate row.

word frequency in description

*  Single word 

```{r, dpi = 300, fig.height = 15}
data(stop_words)
keep_letter_stop_words <- stop_words %>% filter(!word %in% c("C", "c", "R", "r"))

inspection_words_single = 
  datascience %>% 
  unnest_tokens(word, description) %>% 
  anti_join(x = ., keep_letter_stop_words)

inspection_words_single %>% 
  count(word, sort = TRUE) %>% 
  top_n(100) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "single world frequency") +
  coord_flip()
```

*  Double word

```{r, dpi = 300}
data(stop_words)
keep_letter_stop_words <- stop_words %>% filter(!word %in% c("C", "c", "R", "r"))

inspection_words = 
  datascience %>% 
  unnest_tokens(word, description) %>% 
  anti_join(x = ., keep_letter_stop_words)

inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 2) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "double world frequency") +
  coord_flip()

word_cloud2 <- inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 2) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) 

wordcloud(words = word_cloud2$word, freq = word_cloud2$n, random.order=FALSE,
          rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```

*  Three words

```{r, dpi = 300}
inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 3) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "triple world frequency") +
  coord_flip()
```

*  four words

```{r, dpi = 300}
inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 4) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "quadruple world frequency") +
  coord_flip()
```

### Comparing words across groups







