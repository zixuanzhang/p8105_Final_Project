---
title: "read data from Indeed"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = F, 
                      message = F)
library(tidyverse)
library(readr)
library(rvest)
library(stringr)
library(tidytext)
library(wordcloud)
library(RColorBrewer)
library(treemap)
theme_set(theme_bw())
```

## read data (existing)

```{r}
datascience <- read_csv("./data/datascience_market/alldata.csv") %>% 
  filter(!is.na(position))
```

## minimum requirement of degree

```{r, dpi = 300}
pattern_Hi = "[Hh]igh [Ss]chool"
pattern_Ba = "[Bb]achelor | \\bB\\.?A\\b | \\bB\\.?S\\b | [Cc]ollege | [Dd]egree"
pattern_Ma = "[Mm]aster[^y] | [Aa]dvanced | \\bM\\.?[SA]\\b | [Gg]raduate"
pattern_Phd = "\\b[Pp][Hh]\\.?[Dd]\\b | \\bM\\.?D\\b"

datascience %>% 
  mutate(degree = ifelse(str_detect(.$description, pattern_Hi) == TRUE, "high school",
                      ifelse(str_detect(.$description, pattern_Ba) == TRUE, "bachelor",
                          ifelse(str_detect(.$description, pattern_Ma) == TRUE, "master",
                               ifelse(str_detect(.$description, pattern_Phd) == TRUE, "phd", "other"))))) %>% 
  mutate(degree = factor(degree, levels = c("high school", "bachelor", "master", "phd", "other"))) %>% 
  ggplot(aes(x = degree)) + 
  geom_bar() + 
  labs(title = "Minimum degree requirement")
```

## tree map for related background

```{r, dpi = 300}
pattern_bg = c("[Cc]omputer [Ss]cience | \\bC\\.?S\\b | [Mm]achine [Ll]earning | \\bM\\.?L\\b", 
                 "[Ss]tatistic", 
                 "[Mm]ath", 
                 "[Qq]uantitative", 
                 "[Ee]conomic", 
                 "[Bb]iolog", 
                 "[Bb]iostatis", 
                 "[Dd]ata [Ss]cience | \\bD\\.?S\\b", 
                 "[Cc]hemical [Ee]ngineering")
name_bg = c("CS", 
          "Statistics", 
          "Mathematics", 
          "Quantitative", 
          "Economics", 
          "Biology", 
          "Biostatistics", 
          "DS", 
          "Engineer")

bg_freq = data.frame(
  background = pattern_bg, 
  index = name_bg, 
  freq = rep(0, length(pattern_bg))
)

for (i in c(1:length(pattern_bg))) {
  bg_freq$freq[i] = sum(str_detect(datascience$description, as.character(bg_freq$background[i])))
}

bg_freq %>% 
  treemap(index = "index", 
          vSize = "freq", 
          type = "index",
          palette = "Blues")
```

## word frequency count

Took 100 samples from 7000

```{r}
datascience <- mutate(datascience, index = 1:nrow(datascience))
set.seed(1)
sample1 <- sample(1:nrow(datascience), 100, replace = FALSE)
sample1

data_100 <- datascience[sample1,]
```

weâ€™ll un-nest the tokens (i.e. words) in each description; the result is a tidy dataset in which each word is contained within a separate row.

word frequency in description

*  Single word 

```{r, dpi = 300, fig.height = 15}
data(stop_words)
keep_letter_stop_words <- stop_words %>% filter(!word %in% c("C", "c", "R", "r"))

inspection_words_single = 
  datascience %>% 
  unnest_tokens(word, description) %>% 
  anti_join(x = ., keep_letter_stop_words)

inspection_words_single %>% 
  count(word, sort = TRUE) %>% 
  top_n(100) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "single world frequency") +
  coord_flip()
```

*  Double word

```{r, dpi = 300}
data(stop_words)
keep_letter_stop_words <- stop_words %>% filter(!word %in% c("C", "c", "R", "r"))

inspection_words = 
  datascience %>% 
  unnest_tokens(word, description) %>% 
  anti_join(x = ., keep_letter_stop_words)

inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 2) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "double world frequency") +
  coord_flip()
```

word cloud

``` {r, dpi = 300}
word_cloud2 <- inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 2) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) 

wordcloud(words = word_cloud2$word, freq = word_cloud2$n, random.order=FALSE,
          rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```

*  Three words

```{r, dpi = 300}
inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 3) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "triple world frequency") +
  coord_flip()
```

*  four words

```{r, dpi = 300}
inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 4) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "quadruple world frequency") +
  coord_flip()
```

## remove "equality"

```{r}
word = c("race", 
         "age", 
         "religion", 
         "color", 
         "equal", 
         "opportunity", 
         "employer",
         "employment", 
         "sex", 
         "gender", 
         "sexual", 
         "applicant",
         "applicants", 
         "qualification", 
         "qualifications", 
         "qualified", 
         "candidate", 
         "national", 
         "regard", 
         "identity", 
         "veteran", 
         "orientation", 
         "criminal", 
         "minority", 
         "marital", 
         "description")
eq_com = data.frame(
  word = word,
  lexicon = rep("SMART", length(word))
)

keep_letter_stop_words = 
  keep_letter_stop_words %>% 
  full_join(eq_com, key = "word")
```

```{r, dpi = 300}
inspection_words = 
  datascience %>% 
  unnest_tokens(word, description) %>% 
  anti_join(x = ., keep_letter_stop_words)

inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 2) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "double world frequency") +
  coord_flip()
```

```{r, dpi = 300}
inspection_words %>%
  nest(word) %>%
  mutate(text = map(data, unlist), 
         text = map_chr(text, paste, collapse = " ")) %>% 
  select(-data) %>% 
  unnest_tokens(word, text, token = "ngrams", n = 3) %>% 
  count(word, sort = TRUE) %>% 
  top_n(50) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = word, y = n)) + 
  geom_bar(stat = "identity", fill = "blue", alpha = .6) + 
  labs(y = "triple world frequency") +
  coord_flip()
```


### Comparing words across groups
