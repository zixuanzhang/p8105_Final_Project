---
title: "read data from Indeed"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(rvest)
library(httr)
```

### read data (existing)

```{r}
datascience <- read_csv("./data/datascience_market/alldata.csv")

dim(datascience)

head(datascience)

str(datascience)
```

### try scrape data from Indeed

```{r}
read_indeed_pages <- function(url) {
  
   h <- read_html(url_base)
   
  title <- h %>% 
  html_nodes("#resultsCol .jobtitle") %>% 
  html_text()
  
  location <- h %>% 
  html_nodes(".location") %>% 
  html_text()
  
  company <- h %>% 
  html_nodes(".company") %>% 
  html_text()
  
  description <- h %>% 
  html_nodes(".summary") %>% 
  html_text() 

  reviews <- h %>% 
  html_nodes(".slNoUnderline .slNoUnderline") %>% 
  html_text() %>% 
  readr::parse_number()
  
  tibble(title, company, location, description, reviews)
}
```

try reviews (problem: cannot fit in missing values, some job posting do not have reviews)

```{r}
h <- read_html("https://www.indeed.com/jobs?q=data+science&explvl=entry_level")

# grab reviews
h %>% 
  html_nodes(".slNoUnderline .slNoUnderline") %>% 
  html_text() %>% 
  readr::parse_number()

# grab ratings
h %>% 
  html_nodes(".rating")
```

try the function of scraping data (raw data not tidy yet)

```{r}
url_base = "https://www.indeed.com/jobs?q=data+science&start="

vec_urls = str_c(url_base, seq(10, 100, by = 10))
vec_urls

full_data <- map(vec_urls, read_indeed_pages) %>% bind_rows()

full_data
```

