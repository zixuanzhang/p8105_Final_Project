---
title: "Intro_gov_sj.rmd"
author: "Shan Jiang"
date: "11/24/2018"
output: github_document
---

## Data: May 2017 National Occupational Employment and Wage Estimates United States>

## Salary Prospect From 2017 

```{r}
library(tidyverse)
library(readxl)

```


```{r}

national_17 <- read_excel("data/oesm17nat/national_M2017_dl.xlsx")

national_17 %>% View()

national_17 = national_17 %>% 
              janitor::clean_names() %>% 
              filter(str_detect(occ_code, "^[1][5]") | 
                    occ_title == "All Occupations" | 
                    str_detect(occ_code, "^[1][3]") | 
                    str_detect(occ_code, "^[1][9]")) %>% 
              arrange(desc(tot_emp), a_mean)

## Annual Average comparison for different majors 
national_17 %>% 
              janitor::clean_names() %>% 
              filter(occ_group == "major" | occ_group == "total") %>% 
              mutate(occ_title = as.factor(occ_title)) %>% 
              arrange(desc(tot_emp), a_mean) %>% 
              mutate(CI_salary_low = a_mean - mean_prse, 
                     CI_salary_high = a_mean + mean_prse ) %>% 
  ggplot(aes(occ_title, a_mean)) +
    geom_point() + 
  geom_errorbar(ymax = national_17$a_mean +  national_17$mean_rpse , 
                ymin =  national_17$a_mean -  national_17$mean_rpse) +
  theme_bw() +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        axis.text.x = element_text(angle = 90, size = 8),
        legend.key.size = unit(0.05, "cm"))
  
              

national_17 %>% 
filter(occ_code == "13-0000" | 
                    occ_title == "All Occupations" | 
                    occ_code ==  "15-0000" | 
                    occ_code == "19-0000") %>% 
              arrange(desc(tot_emp), a_mean)
  

```

For detetcting the outlook of the computer and math category jobs, we carried out comparison with jobs in some popular fields, such as the 


## Geographical plots and maps 

Import data of state level.

```{r}
state_17 <- read_xlsx("./data/state/oesm17st/state_M2017_dl.xlsx") %>% 
  janitor::clean_names()
 
```

Then we need to combine the datasets from us.state map and our data.  

```{r}
state_17 %>% 
  distinct(state) %>% 
  pull(state) 
```

Since we are making the map of the U.S, we have `nrow(state_17)` entries in our dataset, then we may choose to leave out the data of **Guam**, **Virgin Islands** and the **Puerto Rico** in the convenience of visualization. 

Also, it is far too difficult to create a U.S. state data visualization in R that includes Alaska and Hawaii. 

Then we only keep the computer and mathmatician job classification in our data. 

```{r}

state_clean = state_17 %>%
  filter(str_detect(occ_code, "^[1][5]") ) %>% 
  filter(!state %in% c("Puerto Rico","Guam", "Virgin Islands")) 

```

Now we have `nrow(state_clean)` entries in our dataframe. 

Then we need to generate the geographical information for our dataset. 

```{r}
library(ggmap)
locations_df = 
  state_clean %>% 
  distinct(state) %>% 
  as.tibble() %>% 
  mutate_geocode(state)

```

```{r}
library(leaflet.extras)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)

us_state_map <- map_data("state") %>%
  as_data_frame()
 
ggplot(data = us_state_map) + 
  geom_polygon(aes(x = long, y = lat, fill = region, group = group), color = "white") + 
  coord_quickmap() +
  guides(fill = FALSE) 


plot_usmap(data = state_clean, values = "pop_2015", lines = "red") + 
  scale_fill_continuous(
    low = "white", high = "red", name = "Population (2015)", label = scales::comma
  ) + theme(legend.position = "right")

citation("ggmap")
```

