---
title: "Intro_gov_sj.rmd"
author: "Shan Jiang"
date: "11/24/2018"
output: github_document
---

## Data: May 2017 National Occupational Employment and Salary Estimates United States>

## Reviewing U.S. job market of data scientists in recent 10 years

```{r, include = FALSE}
library(tidyverse)
library(readxl)
```


```{r read and tidy labor data}
#read national Occupational Employment Statistics data
read_national_data = function(file_yr) {
  df = 
  read_excel(str_c("data/national_10yr/national_", file_yr, ".xls")) %>% 
  janitor::clean_names() %>% 
  filter(str_detect(occ_code, "0000$")) %>%
  mutate(year = file_yr) %>% 
  mutate(a_mean = as.numeric(a_mean), 
         a_median = as.numeric(a_median),
         tot_emp = as.numeric(tot_emp),
         mean_prse = as.numeric(mean_prse)) %>% 
  select(year, tot_emp, occ_code, occ_title, a_mean, mean_prse, a_median) 
  
  df
}

#aggregate all 10 years' data in one data frame
national_df = map_df(2008:2017, read_national_data) %>% unnest()

#tidy occupation titles
national_df = 
national_df %>% 
  mutate(occ_title = tolower(occ_title)) %>% 
  mutate(occ_title = str_replace(occ_title, 
                                 "computer and mathematical science occupations", 
                                 "computer and mathematical occupations"),
         occ_title = str_replace(occ_title, 
                                 "community and social service occupations", 
                                 "community and social services occupations"),
         occ_title = str_replace(occ_title, 
                                 "healthcare practitioner and technical occupations", 
                                 "healthcare practitioners and technical occupations")) 

```

The “Occupational Employment Statistics” data bases its classification of occupations on Standard Occupational Classification (SOC). According to this standard, we will refer one of the major categories “Computer and Mathematical Occupations" with SOC code “15-0000” to our occupation of interest “data scientists and data-science-related  professions”, for analysis based on this data in the following.   

```{r 10 yr trend across occupations, dpi = 300}
#plotting the 10-yr trend of median annual salary across all major fields.
national_df %>%
  filter(occ_code != "15-0000") %>% 
  group_by(year) %>% 
  arrange(desc(tot_emp)) %>%
  ggplot(aes(x = year, y = a_median, color = occ_title))+
  geom_line()+
  geom_point()+
  geom_line(data = filter(national_df, occ_code == "15-0000"), color = "black")+
  geom_point(data = filter(national_df, occ_code == "15-0000"), color = "black")+
  labs(x = "Year",
       y = "Mean Annual Salary in dollars",
       color = "Occupation\nTitle",
       title = "10-year trend of median annual salary change across different occupations in the U.S",
       caption = "(based on data from Bureau of Labor Statistics)") +
  scale_x_continuous(breaks = c(2007, 2009, 2011, 2013, 2015, 2017)) +
  theme(legend.position="bottom", 
        legend.text = element_text(size=8))+
  guides(colour = guide_legend(nrow = 8))
```

Ranked the second following “management occupations” since 2011, computer and mathematical-related professions are generally a well-paid working force community in the U.S. In recent 10 years, the median annual salary in this field raised from 71270 dollars to 84560 dollars, with a greater percentage of increase than the national average.   

```{r plotting increment rate, dpi = 300}
#create color panel for plotting
cbbPalette = c( "#CC6666", "#56B4E9", "#009E73","#000000", "#F0E442", "#0072B2", "#E69F00")

#Compare the increment rate of total employment in our selected occupational fields
national_df %>% 
  group_by(occ_code) %>% 
  arrange(year) %>% 
  mutate(increment = ifelse(year == 2008 ,0, diff(tot_emp, 1,1))) %>% 
  mutate(increment_p = increment / tot_emp) %>%
  filter(occ_code %in% c("13-0000",
                         "15-0000",
                         "17-0000",
                         "19-0000",
                         "29-0000",
                         "41-0000",
                         "00-0000"),
         year != "2008") %>%
  ggplot(aes(x = year, y = increment_p*100, color = occ_title))+
  geom_point(aes(size = a_median,  alpha=0.4))+
  scale_size(range = c(0,5))+
  geom_line()+
  labs(size = "Median Annual Salary",
       color = "Occuputation Title",
       x = "Year", 
       y = "Annual percentage increase(%) in total empolyment") + 
  scale_x_continuous(breaks = c(2007, 2009, 2011, 2013, 2015, 2017)) +
  scale_alpha(guide = 'none')+
  scale_colour_manual(values = cbbPalette)

```

Though the median annual salary of data-science related professions follow a trend of steady increase in recent years, the number of total employment in this field since 2014 did not increase as fast as 2010 and 2011. Plotted in black in graph 2, the employment in computer and mathematical field has been increasing at a greater rate than many other professions that generally require qualifications from higher education. Even so, the rate dropped significantly after 2015 and reached below 0 in 2017.  

## Geographical plots and maps 

Import data of state level.

```{r}
state_17 <- read_xlsx("./data/state/oesm17st/state_M2017_dl.xlsx") %>% 
  janitor::clean_names() %>% 
  mutate(a_mean = as.numeric(a_mean)) %>%
  mutate(tot_emp = as.numeric(tot_emp))

## Missing data replaced by mean salary in that specific detailed field for annual salary 
state_df <-  
  state_17 %>% View()
  mutate(a_mean = ifelse(is.na(a_mean), mean(a_mean, na.rm = TRUE), a_mean)) %>% 
  mutate(state = tolower(state))    ## To match the case of state names in 2 dataframe 
```

Then we need to combine the datasets from us.state map and our data.  

```{r}
state_df %>% 
  distinct(state) %>% 
  pull(state) 
```

Since we are making the map of the U.S, we have `nrow(state_17)` entries in our dataset, then we may choose to leave out the data of **Guam**, **Virgin Islands** and the **Puerto Rico** in the convenience of visualization. 

Also, it is far too difficult to create a U.S. state data visualization in R that includes Alaska and Hawaii. 

Then we only keep the computer and mathmatician job classification in our data. 

### spatial map 

```{r}
## Add state salary df.
state_salary <- 
  state_df %>%
  filter(str_detect(occ_code, "15-0000") ) %>% 
  filter(!state %in% c("Puerto Rico","Guam", "Virgin Islands")) %>% 
  group_by(state) %>%
  summarize(abb = st,
            mean_salary = a_mean,
            mean_total = tot_emp,
            mean_job = round(as.numeric(jobs_1000), 2))

```

Now we have `nrow(state_clean)` entries in our dataframe. 

Then we need to generate the geographical information for our dataset. 

```{r}
library(ggplot2)
library(ggmap)
library(fiftystater)
library(plotly)
 
## By using map plotly
states_map <- map_data("state")

state_salary$hover <- 
  with(state_salary, paste(
    "Salary: $", round(mean_salary, 2),'<br>',
            "Total:", mean_total, '<br>',
            "DS Jobs per 1000:", mean_job,'<br>'))

# give state boundaries a white border
l <- list(color = toRGB("white"), width = 2)
# specify some map projection/options
g <- list(
  scope = 'usa',
  projection = list(type = 'albers usa'),
  showlakes = TRUE,
  lakecolor = toRGB('white')
)

p <- plot_geo(state_salary, locationmode = 'USA-states') %>%
  add_trace(
    z = ~ mean_salary, text = ~hover, locations = ~ abb,
    color = ~ mean_salary, colors = 'Oranges'
  ) %>%
  colorbar(title = "$:USD") %>%
  layout(
    title = '2017 US Data Science jobs info by State<br>Source: <a href="https://www.bls.gov/oes/tables.htm">BLS</a>',
    titlefont = 8,
    geo = g
  )

```



## Add team logo 
```{r}
sticker(imgurl2, 
        package = "DS Job Outlook", 
        p_size = 6, s_x = 1.05, s_y = 0.75, s_width =.8,
        h_color = "#000000",  p_color = "black",
        filename = "./data/Figures/team_logo2.png")


```


